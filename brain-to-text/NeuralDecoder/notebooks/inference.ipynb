{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Live Inference"
      ],
      "metadata": {
        "id": "fE7YvLR4sNmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neural_decoder.neural_decoder_trainer import loadModel\n",
        "model = loadModel('/content/drive/MyDrive/TreeHacks/BOO2')\n"
      ],
      "metadata": {
        "id": "6gNy4bjAqpkn"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import firestore\n",
        "\n",
        "\n",
        "cred = credentials.Certificate('/content/treehacks-c0d12-firebase-adminsdk-fbsvc-02119ca686.json')\n",
        "firebase_admin.initialize_app(credential=cred)\n",
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/treehacks-c0d12-firebase-adminsdk-fbsvc-02119ca686.json\"\n"
      ],
      "metadata": {
        "id": "kSh1mG17y_pT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db = firestore.Client()"
      ],
      "metadata": {
        "id": "URtraNxT27-3"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from io import StringIO"
      ],
      "metadata": {
        "id": "6xrbL0Ei1zl0"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "csv_str = db.collection(\"stream\").order_by(\"timestamp\").limit(1).get()[0].to_dict()['brain']\n",
        "inp_stream = StringIO(csv_str)\n",
        "inp = pd.read_csv(inp_stream)\n",
        "\n",
        "inp = inp[inp.columns[:64]]\n",
        "\n",
        "## PREP DATA\n",
        "def inflate_dims(arr, group_size=16):\n",
        "\n",
        "    x, y = arr.shape\n",
        "    mid = y // 2\n",
        "\n",
        "    first_half = arr[:, :mid]\n",
        "    second_half = arr[:, mid:]\n",
        "\n",
        "    result = np.concatenate([\n",
        "        np.repeat(first_half, group_size, axis=1),\n",
        "        np.repeat(second_half, group_size, axis=1)\n",
        "    ], axis=1)\n",
        "\n",
        "    return result\n",
        "\n",
        "dataset = {\n",
        "        'data': inflate_dims(inp.T.values),\n",
        "        'sentenceText': np.array(['hello there',]),\n",
        "        'blockIdx': np.arange(0).repeat(len(inp.T)/20).reshape(-1,1)\n",
        "    }\n",
        "\n",
        "import scipy\n",
        "\n",
        "scipy.io.savemat('/content/tmp.mat', dataset)\n",
        "\n",
        "from g2p_en import G2p\n",
        "\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "\n",
        "g2p = G2p()\n",
        "PHONE_DEF = [\n",
        "    'AA', 'AE', 'AH', 'AO', 'AW',\n",
        "    'AY', 'B',  'CH', 'D', 'DH',\n",
        "    'EH', 'ER', 'EY', 'F', 'G',\n",
        "    'HH', 'IH', 'IY', 'JH', 'K',\n",
        "    'L', 'M', 'N', 'NG', 'OW',\n",
        "    'OY', 'P', 'R', 'S', 'SH',\n",
        "    'T', 'TH', 'UH', 'UW', 'V',\n",
        "    'W', 'Y', 'Z', 'ZH'\n",
        "]\n",
        "PHONE_DEF_SIL = PHONE_DEF + ['SIL']\n",
        "\n",
        "def phoneToId(p):\n",
        "    return PHONE_DEF_SIL.index(p)\n",
        "\n",
        "import scipy\n",
        "\n",
        "def loadFeaturesAndNormalize(sessionPath,type='train'):\n",
        "\n",
        "    dat = scipy.io.loadmat(sessionPath)\n",
        "\n",
        "    input_features = []\n",
        "    transcriptions = []\n",
        "    frame_lens = []\n",
        "    block_means = []\n",
        "    block_stds = []\n",
        "    n_trials = dat['sentenceText'].shape[0]\n",
        "\n",
        "    #collect area 6v tx1 and spikePow features\n",
        "    for i in range(n_trials):\n",
        "        #get time series of TX and spike power for this trial\n",
        "        #first 128 columns = area 6v only\n",
        "        if type == 'train':\n",
        "            features = np.concatenate([dat['tx1'][0,i][:,0:128], dat['spikePow'][0,i][:,0:128]], axis=1)\n",
        "        else:\n",
        "            features = dat['data']\n",
        "\n",
        "        sentence_len = features.shape[0]\n",
        "        sentence = dat['sentenceText'][i].strip()\n",
        "\n",
        "        input_features.append(features)\n",
        "        transcriptions.append(sentence)\n",
        "        frame_lens.append(sentence_len)\n",
        "\n",
        "    #block-wise feature normalization\n",
        "    blockNums = np.squeeze(dat['blockIdx'])\n",
        "    blockList = np.unique(blockNums)\n",
        "    blocks = []\n",
        "    for b in range(len(blockList)):\n",
        "        sentIdx = np.argwhere(blockNums==blockList[b])\n",
        "        sentIdx = sentIdx[:,0].astype(np.int32)\n",
        "        blocks.append(sentIdx)\n",
        "\n",
        "    for b in range(len(blocks)):\n",
        "        feats = np.concatenate(input_features[blocks[b][0]:(blocks[b][-1]+1)], axis=0)\n",
        "        feats_mean = np.mean(feats, axis=0, keepdims=True)\n",
        "        feats_std = np.std(feats, axis=0, keepdims=True)\n",
        "        for i in blocks[b]:\n",
        "            input_features[i] = (input_features[i] - feats_mean) / (feats_std + 1e-8)\n",
        "\n",
        "    #convert to tfRecord file\n",
        "    session_data = {\n",
        "        'inputFeatures': input_features,\n",
        "        'transcriptions': transcriptions,\n",
        "        'frameLens': frame_lens\n",
        "    }\n",
        "\n",
        "    return session_data\n",
        "\n",
        "\n",
        "def getDataset(fileName,type='train'):\n",
        "    session_data = loadFeaturesAndNormalize(fileName,type)\n",
        "\n",
        "    allDat = []\n",
        "    trueSentences = []\n",
        "    seqElements = []\n",
        "\n",
        "    for x in range(len(session_data['inputFeatures'])):\n",
        "        allDat.append(session_data['inputFeatures'][x])\n",
        "        trueSentences.append(session_data['transcriptions'][x])\n",
        "\n",
        "        thisTranscription = str(session_data['transcriptions'][x]).strip()\n",
        "        thisTranscription = re.sub(r'[^a-zA-Z\\- \\']', '', thisTranscription)\n",
        "        thisTranscription = thisTranscription.replace('--', '').lower()\n",
        "        addInterWordSymbol = True\n",
        "\n",
        "        phonemes = []\n",
        "        for p in g2p(thisTranscription):\n",
        "            if addInterWordSymbol and p==' ':\n",
        "                phonemes.append('SIL')\n",
        "            p = re.sub(r'[0-9]', '', p)  # Remove stress\n",
        "            if re.match(r'[A-Z]+', p):  # Only keep phonemes\n",
        "                phonemes.append(p)\n",
        "\n",
        "        #add one SIL symbol at the end so there's one at the end of each word\n",
        "        if addInterWordSymbol:\n",
        "            phonemes.append('SIL')\n",
        "\n",
        "        seqLen = len(phonemes)\n",
        "        maxSeqLen = 500\n",
        "        seqClassIDs = np.zeros([maxSeqLen]).astype(np.int32)\n",
        "        seqClassIDs[0:seqLen] = [phoneToId(p) + 1 for p in phonemes]\n",
        "        seqElements.append(seqClassIDs)\n",
        "\n",
        "    newDataset = {}\n",
        "    newDataset['sentenceDat'] = allDat\n",
        "    newDataset['transcriptions'] = trueSentences\n",
        "    newDataset['phonemes'] = seqElements\n",
        "\n",
        "    timeSeriesLens = []\n",
        "    phoneLens = []\n",
        "    for x in range(len(newDataset['sentenceDat'])):\n",
        "        timeSeriesLens.append(newDataset['sentenceDat'][x].shape[0])\n",
        "\n",
        "        zeroIdx = np.argwhere(newDataset['phonemes'][x]==0)\n",
        "        phoneLens.append(zeroIdx[0,0])\n",
        "\n",
        "    newDataset['timeSeriesLens'] = np.array(timeSeriesLens)\n",
        "    newDataset['phoneLens'] = np.array(phoneLens)\n",
        "    newDataset['phonePerTime'] = newDataset['phoneLens'].astype(np.float32) / newDataset['timeSeriesLens'].astype(np.float32)\n",
        "    return newDataset\n",
        "\n",
        "\n",
        "inp_dataset=getDataset('/content/tmp.mat',type='val')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cv2aFutHsRMH",
        "outputId": "538445d2-59d8-49f2-e5ad-73b581831bd5"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp_loader = torch.utils.data.DataLoader(\n",
        "        SpeechDataset([inp_dataset]), batch_size=1, shuffle=False, num_workers=0\n",
        "    )\n",
        "\n",
        "rnn_outputs = {\n",
        "    \"logits\": [],\n",
        "    \"logitLengths\": [],\n",
        "    \"trueSeqs\": [],\n",
        "    \"transcriptions\": [],\n",
        "}\n",
        "for j, (X, y, X_len, y_len, _) in enumerate(inp_loader):\n",
        "        X, y, X_len, y_len, dayIdx = (\n",
        "            X.to(device),\n",
        "            y.to(device),\n",
        "            X_len.to(device),\n",
        "            y_len.to(device),\n",
        "            torch.tensor([dayIdx], dtype=torch.int64).to(device),\n",
        "        )\n",
        "        pred = model.forward(X, dayIdx)\n",
        "        adjustedLens = ((X_len - model.kernelLen) / model.strideLen).to(torch.int32)\n",
        "\n",
        "        for iterIdx in range(pred.shape[0]):\n",
        "            trueSeq = np.array(y[iterIdx][0 : y_len[iterIdx]].cpu().detach())\n",
        "\n",
        "            rnn_outputs[\"logits\"].append(pred[iterIdx].cpu().detach().numpy())\n",
        "            rnn_outputs[\"logitLengths\"].append(\n",
        "                adjustedLens[iterIdx].cpu().detach().item()\n",
        "            )\n",
        "            rnn_outputs[\"trueSeqs\"].append(trueSeq)\n",
        "\n",
        "        transcript = inp_dataset[\"transcriptions\"][j].strip()\n",
        "        transcript = re.sub(r\"[^a-zA-Z\\- \\']\", \"\", transcript)\n",
        "        transcript = transcript.replace(\"--\", \"\").lower()\n",
        "        rnn_outputs[\"transcriptions\"].append(transcript)"
      ],
      "metadata": {
        "id": "zlxhZeXytYnn"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm, tokenizer = build_gpt2()\n",
        "\n",
        "decoded_transcriptions = decode_rnn_outputs(\n",
        "        rnn_outputs,\n",
        "        model=llm,\n",
        "        tokenizer=tokenizer,\n",
        "        acoustic_scale=1.5,\n",
        "        length_penalty=0.3,\n",
        "        alpha=0.8,\n",
        "        n_best=5\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5H_WNanuOPQ",
        "outputId": "1f15423a-a8fd-491a-c4e8-64ed43eb1662"
      },
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = decoded_transcriptions[0]\n",
        "\n",
        "import openai\n",
        "openai.api_key = # hidden key\n",
        "completion = openai.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"From the natural language thought stream, isolate the web-application prompt: \" + text\n",
        "            },\n",
        "        ],\n",
        "    )"
      ],
      "metadata": {
        "id": "HhgdGvQh6H_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db.collection(\"commands\").document(\"new\").set({\"command\": completion.choices[0].message.content})"
      ],
      "metadata": {
        "id": "zM-RJacWyXfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BkPSG9_H3jAL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}